{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Henry Ginder\n",
    "\n",
    "I am trying different hyper-parameters on the SVM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc(models, model_names):\n",
    "    plt.figure(0, figsize = [8, 7]).clf()\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    \n",
    "    for ii, model in enumerate(models):\n",
    "        y_prob_test = model.predict_proba(X_test_featurized)[:, 1]\n",
    "        fpr, tpr, threshold = roc_curve(y_test, y_prob_test, pos_label = \"yes\")\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "\n",
    "        fpr, tpr, threshold = roc_curve(y_test, y_prob_test, pos_label = \"yes\")\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.plot(fpr, tpr, label = \"{} AUC = {:0.2f}\".format(model_names[ii], roc_auc))\n",
    "\n",
    "    plt.legend(loc = 'lower right');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load and pre-process the data in the same way we did in the lecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Featurized training data has 40689 rows and 51 columns.\n",
      "Featurized test data has 4522 rows and 51 columns.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_admin.</th>\n",
       "      <th>job_blue-collar</th>\n",
       "      <th>job_entrepreneur</th>\n",
       "      <th>job_housemaid</th>\n",
       "      <th>job_management</th>\n",
       "      <th>job_retired</th>\n",
       "      <th>job_self-employed</th>\n",
       "      <th>job_services</th>\n",
       "      <th>job_student</th>\n",
       "      <th>job_technician</th>\n",
       "      <th>...</th>\n",
       "      <th>poutcome_other</th>\n",
       "      <th>poutcome_success</th>\n",
       "      <th>poutcome_unknown</th>\n",
       "      <th>age</th>\n",
       "      <th>balance</th>\n",
       "      <th>day</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.124112</td>\n",
       "      <td>-0.443322</td>\n",
       "      <td>-0.099012</td>\n",
       "      <td>0.231962</td>\n",
       "      <td>0.076064</td>\n",
       "      <td>-0.411045</td>\n",
       "      <td>-0.249556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.510135</td>\n",
       "      <td>-0.314600</td>\n",
       "      <td>-0.459566</td>\n",
       "      <td>-0.581586</td>\n",
       "      <td>-0.244890</td>\n",
       "      <td>-0.411045</td>\n",
       "      <td>-0.249556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.227894</td>\n",
       "      <td>-0.211233</td>\n",
       "      <td>-1.300857</td>\n",
       "      <td>-0.126155</td>\n",
       "      <td>-0.565844</td>\n",
       "      <td>-0.411045</td>\n",
       "      <td>-0.249556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.039734</td>\n",
       "      <td>0.230193</td>\n",
       "      <td>-0.699935</td>\n",
       "      <td>-0.130048</td>\n",
       "      <td>-0.565844</td>\n",
       "      <td>-0.411045</td>\n",
       "      <td>-0.249556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.653711</td>\n",
       "      <td>0.134627</td>\n",
       "      <td>-1.421042</td>\n",
       "      <td>0.391557</td>\n",
       "      <td>-0.565844</td>\n",
       "      <td>1.216026</td>\n",
       "      <td>0.615550</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   job_admin.  job_blue-collar  job_entrepreneur  job_housemaid  \\\n",
       "0         0.0              0.0               0.0            1.0   \n",
       "1         0.0              0.0               0.0            0.0   \n",
       "2         0.0              1.0               0.0            0.0   \n",
       "3         0.0              0.0               0.0            0.0   \n",
       "4         0.0              0.0               0.0            0.0   \n",
       "\n",
       "   job_management  job_retired  job_self-employed  job_services  job_student  \\\n",
       "0             0.0          0.0                0.0           0.0          0.0   \n",
       "1             1.0          0.0                0.0           0.0          0.0   \n",
       "2             0.0          0.0                0.0           0.0          0.0   \n",
       "3             0.0          0.0                0.0           1.0          0.0   \n",
       "4             1.0          0.0                0.0           0.0          0.0   \n",
       "\n",
       "   job_technician  ...  poutcome_other  poutcome_success  poutcome_unknown  \\\n",
       "0             0.0  ...             0.0               0.0               1.0   \n",
       "1             0.0  ...             0.0               0.0               1.0   \n",
       "2             0.0  ...             0.0               0.0               1.0   \n",
       "3             0.0  ...             0.0               0.0               1.0   \n",
       "4             0.0  ...             0.0               0.0               0.0   \n",
       "\n",
       "        age   balance       day  duration  campaign     pdays  previous  \n",
       "0 -1.124112 -0.443322 -0.099012  0.231962  0.076064 -0.411045 -0.249556  \n",
       "1  1.510135 -0.314600 -0.459566 -0.581586 -0.244890 -0.411045 -0.249556  \n",
       "2  1.227894 -0.211233 -1.300857 -0.126155 -0.565844 -0.411045 -0.249556  \n",
       "3  1.039734  0.230193 -0.699935 -0.130048 -0.565844 -0.411045 -0.249556  \n",
       "4 -0.653711  0.134627 -1.421042  0.391557 -0.565844  1.216026  0.615550  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bank = pd.read_csv(\"./data/bank-full.csv\", sep = \";\")\n",
    "\n",
    "# seperate columns by type\n",
    "num_cols = bank.select_dtypes(['integer', 'float']).columns\n",
    "cat_cols = bank.select_dtypes(['object']).drop(columns = \"y\").columns\n",
    "\n",
    "# split data to training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(bank.drop(columns = \"y\"), bank[\"y\"], \n",
    "                                                    test_size = 0.10, random_state = 42)\n",
    "# reset index\n",
    "X_train = X_train.reset_index(drop = True)\n",
    "X_test = X_test.reset_index(drop = True)\n",
    "\n",
    "# one hot encode categorical columns\n",
    "onehoter = OneHotEncoder(sparse = False)\n",
    "onehoter.fit(X_train[cat_cols])\n",
    "onehot_cols = onehoter.get_feature_names_out(cat_cols)\n",
    "X_train_onehot = pd.DataFrame(onehoter.transform(X_train[cat_cols]), columns = onehot_cols)\n",
    "X_test_onehot = pd.DataFrame(onehoter.transform(X_test[cat_cols]), columns = onehot_cols)\n",
    "\n",
    "# normalize numeric columns\n",
    "znormalizer = StandardScaler()\n",
    "znormalizer.fit(X_train[num_cols])\n",
    "X_train_norm = pd.DataFrame(znormalizer.transform(X_train[num_cols]), columns = num_cols)\n",
    "X_test_norm = pd.DataFrame(znormalizer.transform(X_test[num_cols]), columns = num_cols)\n",
    "\n",
    "# concatenate one hot encoded cateorical type columns with normalized numeric columns\n",
    "X_train_featurized = X_train_onehot # add one-hot-encoded columns\n",
    "X_test_featurized = X_test_onehot   # add one-hot-encoded columns\n",
    "X_train_featurized[num_cols] = X_train_norm # add numeric columns\n",
    "X_test_featurized[num_cols] = X_test_norm   # add numeric columns\n",
    "\n",
    "del X_train_norm, X_test_norm, X_train_onehot, X_test_onehot\n",
    "\n",
    "logit = LogisticRegression(max_iter = 5000, solver = 'lbfgs')\n",
    "logit.fit(X_train_featurized, y_train)\n",
    "\n",
    "y_hat_train = logit.predict(X_train_featurized)\n",
    "y_hat_test = logit.predict(X_test_featurized)\n",
    "\n",
    "print(\"Featurized training data has {} rows and {} columns.\".format(*X_train_featurized.shape))\n",
    "print(\"Featurized test data has {} rows and {} columns.\".format(*X_test_featurized.shape))\n",
    "\n",
    "X_train_featurized.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are three main ways to search the **hyper-parameter space**:\n",
    "\n",
    "- **Grid search:** tries every combination of hyper-parameters\n",
    "- **Random search:** tries a random subset of all combinations of hyper-parameters\n",
    "- **Bayesian optimization:** tries a subset of all combinations of hyper-parameters (like random search) but does so in a more intelligent way, based on trading off the need to **explore** (trying a part of the hyper-parameter space thus far unexplored) and the need to **exploit** (focusing on a part of the hyper-parameter space that thus far seems promising)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "hps = {'kernel': ['linear', 'rbf'], 'C': [1, 15], 'gamma': ['scale', 'auto', 0.1]}#'degree': [2, 3, 4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I removed the degree portion from the hyperparameters dictionary ( as well as the 'poly' value within the 'kernel' key) because after countless runs I didn't see 'poly' chosen once, and from the documentation for SVC() I read that the 'degree' parameter only affects 'poly'-kernel models. I did this to makes running the notebook take slightly less time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53.333333333333336"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(3.2e9) / (5 * 12) / 1e6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Approximate the cache size for each model in the GridSearch. Jupyter notebooks have about 3.2 gigabytes of memory. Divide by total models we are gonna create, 5 fold times 15 potential combinations. Then divide by a million to get value in megabytes, which is how it expects it based on the documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "gscv = GridSearchCV(SVC(max_iter=-1, class_weight='balanced', cache_size=51, probability=False), param_grid=hps, verbose=2, cv=5, refit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the GridSearchCV() object. Max_iter="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model with gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 12 candidates, totalling 24 fits\n",
      "[CV] END ....................C=1, gamma=scale, kernel=linear; total time=  32.7s\n",
      "[CV] END ....................C=1, gamma=scale, kernel=linear; total time=  36.2s\n",
      "[CV] END .......................C=1, gamma=scale, kernel=rbf; total time=  34.3s\n",
      "[CV] END .......................C=1, gamma=scale, kernel=rbf; total time=  33.0s\n",
      "[CV] END .....................C=1, gamma=auto, kernel=linear; total time=  32.1s\n",
      "[CV] END .....................C=1, gamma=auto, kernel=linear; total time=  32.6s\n",
      "[CV] END ........................C=1, gamma=auto, kernel=rbf; total time=  31.7s\n",
      "[CV] END ........................C=1, gamma=auto, kernel=rbf; total time=  31.5s\n",
      "[CV] END ......................C=1, gamma=0.1, kernel=linear; total time=  31.9s\n",
      "[CV] END ......................C=1, gamma=0.1, kernel=linear; total time=  32.2s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=  32.7s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=  32.8s\n",
      "[CV] END ...................C=15, gamma=scale, kernel=linear; total time= 3.4min\n",
      "[CV] END ...................C=15, gamma=scale, kernel=linear; total time= 3.4min\n",
      "[CV] END ......................C=15, gamma=scale, kernel=rbf; total time=  47.0s\n",
      "[CV] END ......................C=15, gamma=scale, kernel=rbf; total time=  52.4s\n",
      "[CV] END ....................C=15, gamma=auto, kernel=linear; total time= 3.3min\n",
      "[CV] END ....................C=15, gamma=auto, kernel=linear; total time= 3.4min\n",
      "[CV] END .......................C=15, gamma=auto, kernel=rbf; total time=  32.4s\n",
      "[CV] END .......................C=15, gamma=auto, kernel=rbf; total time=  33.0s\n",
      "[CV] END .....................C=15, gamma=0.1, kernel=linear; total time= 3.5min\n",
      "[CV] END .....................C=15, gamma=0.1, kernel=linear; total time= 3.5min\n",
      "[CV] END ........................C=15, gamma=0.1, kernel=rbf; total time=  53.3s\n",
      "[CV] END ........................C=15, gamma=0.1, kernel=rbf; total time=  51.6s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, estimator=SVC(cache_size=51, class_weight='balanced'),\n",
       "             param_grid={'C': [1, 15], 'gamma': ['scale', 'auto', 0.1],\n",
       "                         'kernel': ['linear', 'rbf']},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "gscv.fit(X_train_featurized, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 15, 'gamma': 0.1, 'kernel': 'rbf'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_score = gscv.cv_results_['mean_test_score'].max()\n",
    "max_index = list(gscv.cv_results_['mean_test_score']).index(max_score)\n",
    "gscv.cv_results_['params'][max_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the precision and recall of the best estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision = 65% and recall = 35% on the training data.\n",
      "Precision = 63% and recall = 34% on the validation data.\n"
     ]
    }
   ],
   "source": [
    "precision_train = precision_score(y_train, y_hat_train, pos_label = 'yes') * 100\n",
    "precision_test = precision_score(y_test, y_hat_test, pos_label = 'yes') * 100\n",
    "\n",
    "recall_train = recall_score(y_train, y_hat_train, pos_label = 'yes') * 100\n",
    "recall_test = recall_score(y_test, y_hat_test, pos_label = 'yes') * 100\n",
    "\n",
    "print(\"Precision = {:.0f}% and recall = {:.0f}% on the training data.\".format(precision_train, recall_train))\n",
    "print(\"Precision = {:.0f}% and recall = {:.0f}% on the validation data.\".format(precision_test, recall_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9027009756936765"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_train, y_hat_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8949579831932774"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_hat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=15, cache_size=51, class_weight='balanced', gamma=0.1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gscv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision = 66% and recall = 98% on the training data.\n",
      "Precision = 49% and recall = 71% on the validation data.\n"
     ]
    }
   ],
   "source": [
    "gscv_train_predict = gscv.predict(X_train_featurized)\n",
    "gscv_test_predict = gscv.predict(X_test_featurized)\n",
    "\n",
    "precision_train = precision_score(y_train, gscv_train_predict, pos_label = 'yes') * 100\n",
    "precision_test = precision_score(y_test, gscv_test_predict, pos_label = 'yes') * 100\n",
    "\n",
    "recall_train = recall_score(y_train, gscv_train_predict, pos_label = 'yes') * 100\n",
    "recall_test = recall_score(y_test, gscv_test_predict, pos_label = 'yes') * 100\n",
    "\n",
    "print(\"Precision = {:.0f}% and recall = {:.0f}% on the training data.\".format(precision_train, recall_train))\n",
    "print(\"Precision = {:.0f}% and recall = {:.0f}% on the validation data.\".format(precision_test, recall_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9388532527218658"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_train, gscv_train_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8721804511278195"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, gscv_test_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very cool!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Henry Ginder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
